目标检测是计算机视觉领域的核心问题之一，其主要任务在对图像准确进行分类的基础上，找出图像中的某些目标，并标识它们的位置和大小。

### YOLO算法

图像分类问题常采用Softmax回归来解决，且训练集的标签都是以one-hot形式进行表示。希望在此基础上对图像中的某些目标进行定位，则需要对标签的表示形式做出一些调整。

![定位表示](https://ws1.sinaimg.cn/large/82e16446ly1fnxiefqv4uj214e0j7jxa.jpg)

如上图为例，原先的分类问题中，目标是把输入的图像分成行人、汽车、摩托车、背景这$4$类。输出某张图像后，CNN最后的Softmax单元将输出一个$4$维列向量，向量中各元素的值分别代表图像中各类存在的概率。

进一步处理上例中已有的图像数据：当图片中存在行人、汽车、摩托车这几类目标时，标注这几类目标的位置和大小。标注时，可将一张图片的左上角设为坐标$(0, 0)$，右下角设为坐标$(1, 1)$，之后分别用以下符号标识图片中某个目标的位置以及大小信息：
* $(b_x, b_y)$：目标的中点坐标
* $b_h$：目标的高度
* $b_w$：目标的宽度

有了这些信息，就可以像上图中那样，用一个方形Bounding Box标识出图像中的目标位置。则在上例中加入目标定位任务后，一张图片的标签可以表示为：$$y = \begin{bmatrix} p_c \\\ b_x \\\ b_y \\\ b_h \\\ b_w \\\ c_1 \\\ c_2 \\\ c_3 \\\ c_4 \end{bmatrix}$$

其中$p_c$表示图像中存在这几类目标的概率，$c_1$、$c_2\cdots$则表示图像各类存在的概率，就是原来只进行分类时的标签。

图像中存在某类目标时$p_c = 1$，否则$p_c = 0$。在$p_c = 0$时标签中剩下的其他值都是意义的。因此，如果使用最简单的均方误差计算成本，将有：
$$\mathcal{L}(\hat{y},y) = \begin{cases} (\hat{p}_{c} - p_{c})^2 + (\hat{b}_x- b_x)^2 + ... +(\hat{c}_4 - c_4)^2 ,  & \text{$(p_c = 1)$} \\\ (\hat{p_c}-p_c)^2, & \text{$(p_c = 0)$} \end{cases}$$

另外，如需检测某幅图像中的某些特征点，例如一张人脸图像中五官的各个位置，可以用多个二维坐标标记这些特征点，并将这些坐标都加入图像数据的标签中。

![滑动窗口](https://ws1.sinaimg.cn/large/82e16446ly1fo10q4530uj213d0gntek.jpg)

如上图所示，所谓的**滑窗检测（Sliding Windows Detection）**，就是在图像上不断滑动一个特定大小（小于输入图像大小）窗口，而不断截取图像的一小部分后，分别进行处理，这是实现目标检测的一种简单算法。

然而对每一小部分都进行一次处理，如果使用的是一般的神经网络，将造成巨大的开销。可以发现，滑窗检测的过程与CNN中的进行卷积运算时的过程十分类似，而该算法其实就可以在CNN中高效地实现，

![滑动检测](https://ws1.sinaimg.cn/large/82e16446gy1fo275wzl7dj21340dg0zd.jpg)

在卷积网络中实现滑窗检验的过程如上图。向之前的示例中输入一个更大的图像，而保持各层卷积核的大小不变，最后的输出结果大小为2×2×4，也就相当于用一个大小为14×14的窗口，以2个单位的步长，在输入的图像中进行滑窗检测后得到的结果，图中对此用不同的颜色进行了标识。

其实，在滑动窗口的过程中可以发现，卷积过程的很多很多计算都是重复的。用卷积网络实现滑动窗口检验，减少了重复的计算，从而提高了效率。这样一个方法，是Sermanet等人2014年在论文[[OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks]](https://arxiv.org/pdf/1312.6229.pdf)中提出来的。

采用滑窗检测进行目标检测，难以选取到一个可以完美匹配目标位置的，大小合适的窗口。

**YOLO（You Only Look Once）算法**是Redmon等人2015年在论文[[You Only Look Once: Unified, Real-Time Object Detection]](https://arxiv.org/pdf/1506.02640.pdf)中提出的另一种用于目标检测的算法。

YOLO算法中，将输入的图像划分为S×S个网格（Grid Cell)，对这S×S个网格分别指定一个标签，标签的形式如前面所述：
* $p_c$标识该网格中的目标存在与否。为“1”则表示存在；“0”则表示不存在，且标签中其他值都无效。
* $b_x$、$b_y$表示包围盒的中心坐标值，它们相对于该网格进行了归一化，也就是它们的取值范围在0到1之间；
* $b_h$、$b_w$表示包围盒的长度和宽度；
* $c_n$表示第n个假定类别存在的概率。

某个目标的中点落入某个网格，该网格就负责检测该对象。

![YOLO](https://ws1.sinaimg.cn/large/82e16446gy1fo3c0ss4nnj218n0l4h31.jpg)

如上面的示例中，如果将输入的图片划分为3×3个网格、需要检测的类别有3类，则每一网格部分图片的标签会是一个8维的列矩阵，最后输出结果的大小就是3×3×8。要得到这个结果，就要训练一个输入大小为100×100×3，输出大小为3×3×8的卷积神经网络。

预测出的目标位置的准确程度用**IOU（Intersection Over Union）**来衡量，它表示预测出的包围盒（Bounding Box）与实际边界（Ground Truth）的重叠度，也就是两个不同包围盒的交并比。如下图中所示，IOU就等于两个包围盒的交集面积（黄色部分）占两个包围盒的并集面积（绿色部分）的比率。一般可以约定一个阈值，以此判断预测的包围盒的准确与否。

![IOU值](https://ws1.sinaimg.cn/large/82e16446gy1fo3diqi5z2j211d0fftfb.jpg)

使用YOLO算法进行目标检测，因为是多个网格对某些目标同时进行检测，很可能会出现同一目标被多个网格检测到，并生成多个不同的包围盒的情况，这时需要通过**非极大值抑制（Non-max Suppression）**来筛选出其中最佳的那个。

对于每一个网格，将通过一个**置信度评分（Confidence Scores）**来评判该网格检测某个目标的准确性，这个评分值为$p_c$值与各$c_n$值的乘积中的最大值，也就是说每个包围盒将分别对应一个评分值。进行非极大值抑制的步骤如下：
1. 选取拥有最大评分值的包围盒；
2. 分别计算该包围盒与所有其他包围盒的IOU值，将所有IOU超过预设阈值的包围盒丢弃；
3. 重复以上过程直到不存在比当前评分值更小的包围盒。

上述算法只适用于单目标检测，也就是每个网格只能检测一个对象。要将该算法运用在多目标检测上，需要用到**Anchor Boxes**。在原单目标检测所用的标签中加入其他目标的标签，每个目标的标签表示形式都如上所述，一组标签即标明一个Anchor Box，则一个网格的标签中将包含多个Anchor Box，相当于存在多个用以标识不同目标的包围盒。

![Anchor Box](https://ws1.sinaimg.cn/large/82e16446gy1fo6t2zsxcqj213p0luqdv.jpg)

如上面的例子中，还是将输入的图片划分为3×3个网格且检测的类别为3类。希望同时检测人和汽车，则每个网格的标签中要含有两个Anchor Box，每一网格部分图片的标签会是一个16维的列矩阵，最后输出结果的大小就是3×3×16。

单目标检测中，图像中的目标被分配给了包含该目标的中点的那个网格；引入Anchor Box进行多目标检测，图像中的目标则被分配到了包含该目标的中点的那个网格以及具有最高IOU值的网格的Anchor Box。

### RCNN

**RCNN（Region CNN)**是Girshick等人2013年在论文[[Rich feature hierarchies for accurate object detection and semantic segmentation]](https://arxiv.org/pdf/1311.2524.pdf)中提出的一种目标检测算法，其中提出的**候选区域（Region Proposal）**概念在计算机视觉领域有很大的影响力，它可以说是利用深度学习进行目标检测的开山之作。

R-CNN意为带区域的卷积网络，类似之前所述的滑窗检测算法，先用卷积网络训练一个能够准确识别目标的分类器，但这个算法试图选出一些区域为候选区域，只在这些区域也就是只在少数的窗口上运行分类器。候选区域的选取采用的是一种称为图像分割的算法。

后续有一系列的研究工作，试图改进这个算法，而出现了Fast R-CNN、Faster R-CNN算法，不过（Andrew Ng认为）这些算法在运行速度方面还是不如YOLO算法。



***
#### 相关程序

#### 参考资料
1. [吴恩达-卷积神经网络-网易云课堂](http://mooc.study.163.com/course/2001281004#/info)
2. [Andrew Ng-Convolutional Neural Networks-Coursera](https://www.coursera.org/learn/convolutional-neural-networks/)
3.  [YOLO——基于回归的目标检测算法-csdn](http://blog.csdn.net/btbujhj/article/details/75020217)
4.  [非极大值抑制-csdn](http://blog.csdn.net/u011534057/article/details/51235718)
5.  [RCNN算法详解-csdn](http://blog.csdn.net/shenxiaolu1984/article/details/51066975)
6.  [“看懂”卷积神经网-csdn](http://blog.csdn.net/xjz18298268521/article/details/52381830)

#### 更新历史
* 2019.04.20 完成初稿
