### 数据划分
想用机器学习算法解决某些实际问题，就需要准备大量与问题相关的数据。有了数据集之后，直接用所有的数据来训练机器学习模型显然不是一个明智之举。在训练模型前，首先需要考虑如何对数据集进行划分。

通常的做法，是取数据集中的大部分作为**训练集（Training Sets）**，将这些数据来训练模型，预留其中的一小部分作为**测试集（Test Sets）**，用它们来评估训练出来的模型的**泛化（generalization）**能力。然而，训练出来的模型在实际的应用面对的往往都是与训练、测试样本大相径庭的数据，单单利用测试集来评估模型，很容易导致训练出来的模型只是在这一小部分数据上表现优异，而无法知晓模型真实的泛化能力。

![数据划分](https://i.loli.net/2019/05/05/5cce9efea5230.jpg)

较好也是目前常用的数据划分方法，是将已有的数据集划分为三个部分——训练集、**验证集（Validation Sets）**和测试集。采用训练集进行训练后，对调参后产生的几种不同的模型，用验证集来筛选出其中的性能最优者，之后再用测试集对模型的性能做出评估，这样训练出来的模型才能一定的性能保障。此外，还要尽量保证验证集和测试集的来源一致。

### 数据标准化 
训练机器学习模型前，通常要对数据作一定的处理。其中必不可少的一项工作，就是对所有数据进行**标准化（normalization）**，将所有的数据按比例缩放，使它们都落在一个较小的特定空间内，这样可以有效提高训练模型时的收敛速度。例如，标准化之后可以有效较少下图中梯度下降的迭代次数：

![标准化](https://i.loli.net/2019/05/05/5cce9f0c9514f.jpg)

常见的几种数据标准化方法有：
1. min-max标准化：

    $$x_i := \frac{x_i - \text{min}(x)}{\text{max}(x)-\text{min}(x)}$$

    通过上式进行标准化后，数据都落到区间$[0,1]$内且无量纲。如果要使数据落在区间$[-1,1]$内，可使用下式：
    $$x_i := \frac{x_i - \text{average}(x)}{\text{max}(x)-\text{min}(x)}$$

2. z-score标准化：

    先计算所有数据的均值、标准差：
    $$ \mu = \frac{1}{m} \sum_{i=1}^m x_i, \ \ \  \sigma = \sqrt{\frac{1}{m} \sum_{i=1}^m (x_i - \mu)^2}$$ 

    则：
    $$ x_i := \frac{x_i - \mu}{\sigma}$$  

    通过上式进行标准化后，数据服从均值为$0$，方差为$1$的正态分布。

***
#### 参考资料
1. [吴恩达-改善深层神经网络-网易云课堂](http://mooc.study.163.com/course/deeplearning_ai-2001281003#/info)
2. [Andrew Ng-Improving Deep Neural Networks-Coursera](https://www.coursera.org/learn/deep-neural-network/)
3. [斯坦福-CS231n(2017)-网易云课堂](https://study.163.com/course/introduction/1004697005.htm)
4. [数据标准化/归一化-CSDN](https://blog.csdn.net/pipisorry/article/details/52247379)

#### 更新历史
* 2019.04.13 完成初稿
