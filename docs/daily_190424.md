---
title: 每日总结（VOL.5）
top_img: https://ws1.sinaimg.cn/large/82e16446ly1g2bpkh75aij20m80ciguf.jpg
date: 2019-04-24
tags:
- Daily
---
每日总结190424
<!--more-->
### YOLOv1 paper
1. 创新点：
   先前都是目标检测都在分类器的基础上实现，YOLO中把目标检测当成回归问题，并从空间上分割bounding boxes和相关类别的概率。（we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities.）

2. YOLO的基本工作流程：
  ![工作流程](https://i.loli.net/2019/04/24/5cbfd5cd957e5.png)
     * 将输入的图片大小设为$448 \times 448$
     * 用CNN进行处理
     * 进行非极大值抑制（Non-max suppression）

3. YOLO的优点：
   * 运行速度很快，Titan X GPU上可以达到45FPS，可用来进行实时检测，且平均准确率比其他实时系统高于两倍以上
   * 在完整的图像上全面进行推理预测，隐式地对关于类的上下文以及它们的外观信息进行编码（it implicitly encodes contextual information about classes as well as their appearance）
   * 学习到的是目标的泛化表示，因此泛化能力较强
  
4. 基本思路：
   * 将输入的图片分为$S \times S$个网格，目标的中心所在的网格负责检测该目标
   * 每个网格预测出$B$个bounding boxes以及它们各自的置信度（confidence scores），置信度的大小反映了预测出的bouning boxes以及其中包含某个目标的可靠度。该置信度在形式上被定义为$\text{Pr(Object)}  \cdot \text{IOU}^{\text{truth}}_{\text{pred}}$，即不存在目标时置信度应当为$0$，否则希望得到置信度等于预测出的box于真实box之间的IOU
   * 每个bounding box除了置信度外还包含$x$、$y$、$w$、$h$这几个预测值，$(x, y)$表示目标的bounding box的中心点相对于其对应的网格的坐标，$w$、$h$则是目标相对于整个图像的宽度和高度
   * 每个网格还要预测该网格种存在某个目标的条件下，$C$种类型的目标存在的概率，即$\text{Pr}(\text{Class}_i \vert \text{Object})$。尽管一个网格中存在多个bounding boxes，只预测一组各类别的存在概率。
   * 在测试时有：$$\text{Pr}(\text{Class}_i \vert \text{Object}) \cdot \text{Pr}(\text{Object}) \cdot \text{IOU}^{\text{truth}}_{\text{pred}} = \text{Pr}(\text{Class}_i) \cdot \text{IOU}^{\text{truth}}_{\text{pred}}$$
     这样将得到各box中各类目标的置信度，该置信度同时说明了box中存在某类目标的概率以及box与该目标的匹配程度。
   * 这样，整个模型预测出来的结果大小将为$S \times S \times (B \cdot 5 + C)$:
    ![Model](https://i.loli.net/2019/04/24/5cbfe84fd69b6.png)
    作者在包含$20$种类型的PASCAL VOC数据集上测试的YOLO，用到的$S = 7$、$B = 2$ $C = 20$，因此输出的大小为$7 \times 7 \times 30$

5. 实现细节：
   * 整个CNN的结构受GoogLeNet影响，整个YOLO网络由$24$个卷积层、$2$个全连接层构成，与GoogLeNet种的Inception结构稍有不同，这里只用到了$1\times1$、$3 \times 3$卷积：
   ![20190424151209.png](https://i.loli.net/2019/04/24/5cc00c4dd0368.png)
   * 首先使用了ImageNet千类竞赛数据集对CNN进行了预训练，预训练时用到了前$20$个卷积层外加一个平均池化层和一个全连接层。经过一个星期的训练后，在ImageNet 2012的验证集上获得了单一裁剪图上$88\%$的top-5准确率。所有训练过程都是用Darknet框架完成。后面参考他人的研究，再添加了$4$个卷积层和$2$个全连接层，其中的权重进行的是随机初始化。
   * 最后一层要输出各类型概率以及bounding box的坐标。通过图像的带大小将bounding box的大小进行了标准化，从而使长度和宽度都在$0$到$1$之间。各box的中心坐标$x$和$y$被参数化为各网格单元位置的偏移量，从而它们的值也在$0$到$1$之间。
   * 除最后一层用的是线性激活函数外，其他各层由用的如下Leaky-ReLU：$$\phi(x) = \begin{cases} x, & x \gt 0 \\\ 0.1x, & \text{otherwise} \end{cases}$$
   * 因为均方误差优化起来很方便，因此选用它为损失函数。然而这会使分类带来的误差与定位带来误差的权重一致，且在不包含任何目标的网格上，置信度很快被置为$0$，往往会使包含目标的网格上的梯度变化剧烈，而造成模型不稳定而在训练的早期就发散。为修正这些问题，于是用参数$\lambda_{\text{coord}} = 5$来增加由bounding box的坐标预测带来的损失，参数$\lambda_{\text{noobj}} = 0.5$来降低不包含目标时带来的损失
   * 均方误差还会使大boxes和小boxes的预测上带来误差的权重一致，误差的衡量标准应该：比起小boxes，对大boxes的预测上出现一些小偏差更可以接受。为实现这个标准，于是使模型预测输出bounding box高度、宽度的平方根而非直接的高度、宽度。
   * 每个网格中将多个bounding boxes预测器，然而训练过程中只希望各目标各由一个bounding box预测器负责，因此将某个目标的检测任务分配给当前预测出来的bounding box和真实box的IOU值最大的那个预测器负责。
   * 用到的损失函数的完整表达式：
    ![损失函数](https://i.loli.net/2019/04/24/5cc01cfc7f886.png)
    其中$\mathbb{1}_i^{\text{obj}}$代表目标是否存在第$i$个网格上且$\mathbb{1}_{ij}^{\text{obj}}$则代表第$i$个网格中预测任务由其中的第$j$个bounding box预测器负责。注意到，当目标只是存在于某个网格中时，损失函数只对其分类错误作出惩罚，如果某个网格中存在负责预测实际边框的预测器，则仅对其bounding box坐标预测错误作出惩罚。
   * YOLO网络在PASCAL VOC 2007、2012的训练集和验证集上训练了135 epochs， 训练过程的批量大小为$64$，动量为$0.9$及$0.0005$的衰减。为防止初始时学习率过高导致梯度不稳定，训练第一个epoch时，慢慢将学习率从$10^{-3}$提升到$10^{-2}$，之后用$10^{-2}$训练$75$个epochs，$10^{-3}$训练$30$个epochs，最后用$10^{-4}$训练$30$个epochs。为防止过拟合，在第一个全连接层后使用了$0.5$比例的Dropout，还用到了一些方法进行数据扩增。

### CS20-Lecture4
#### MNIST with Softmax Regression
另外两种迭代器：
* tf.data.Iterator.form_structure(training_dataset.output_types, training_dataset.output_shapes) 可重新初始化迭代器，可以通过多个不同的 Dataset对象进行初始化
* tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes) 可馈送迭代器 其中handle = tf.placeholder(tf.string, shape=[])
  
实现过程：
```python
# 建模

learning_rate = 0.01
batch_size = 128
n_epochs = 30
n_train = 60000
n_test = 10000

train, val, test = read_mnist('./data/mnist', flatten=True)
train_data = tf.data.Dataset.from_tensor_slices(train)
train_data = train_data.shuffle(10000) # 随机打乱
train_data = train_data.batch(batch_size) # 小批量

test_data = tf.data.Dataset.from_tensor_slices(test)
test_data = test_data.batch(batch_size)

iterator = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes) # 迭代器
img, label = iterator.get_next()

train_init = iterator.make_initializer(train_data) # 初始化迭代器
test_init = iterator.make_initializer(test_data)

w = tf.get_variable(name='weights', shape=(784, 10), initializer=tf.random_normal_initializer(0, 0.01)) # 随机初始化
b = tf.get_variable(name='bais', shape=(1, 10), initializer=tf.zeros_initializer())
logits = tf.matmul(img, w) + b
entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels = label, name='entropy') # 交叉熵
loss = tf.reduce_mean(entropy, name='loss') # 平均

optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss) # Adam梯度下降

preds = tf.nn.softmax(logits) # 预测
correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1)) # 比较索引
accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))

# 训练

writer = tf.summary.FileWriter('./graphs/logreg', tf.get_default_graph())
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer()) # variables初始化
    
    for i in range(n_epochs):
        sess.run(train_init) # 训练集初始化
        total_loss = 0
        n_batches = 0
        try:
            while True:
                _, l = sess.run([optimizer, loss])
                total_loss += l
                n_batches += 1
        except tf.errors.OutOfRangeError:
            pass
        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))
    
    sess.run(test_init) # 初始化测试集
    total_correct_preds = 0
    try:
        while True:
            accuracy_batch = sess.run(accuracy)
            total_correct_preds += accuracy_batch
    except tf.errors.OutOfRangeError:
        pass
    
    print('Accuracy {0}'.format(total_correct_preds/n_test))
writer.close()

```
生成的graphs：
![graphs](https://i.loli.net/2019/04/24/5cc05c587b106.png)

