---
title: 每日总结（VOL.5）
top_img: https://ws1.sinaimg.cn/large/82e16446ly1g2bpkh75aij20m80ciguf.jpg
date: 2019-04-24
tags:
- Daily
---
每日总结190424
<!--more-->
### YOLOv1 paper
1. 创新点：
   先前都是目标检测都在分类器的基础上实现，YOLO中把目标检测当成回归问题，并从空间上分割bounding boxes和相关类别的概率。（we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities.）

2. YOLO的基本工作流程：
  ![工作流程](https://i.loli.net/2019/04/24/5cbfd5cd957e5.png)
     * 将输入的图片大小设为$448 \times 448$
     * 用CNN进行处理
     * 进行非极大值抑制（Non-max suppression）

3. YOLO的优点：
   * 运行速度很快，Titan X GPU上可以达到45FPS，可用来进行实时检测，且平均准确率比其他实时系统高于两倍以上
   * 在完整的图像上全面进行推理预测，隐式地对关于类的上下文以及它们的外观信息进行编码（it implicitly encodes contextual information about classes as well as their appearance）
   * 学习到的是目标的泛化表示，因此泛化能力较强
  
4. 基本思路：
   * 将输入的图片分为$S \times S$个网格，目标的中心所在的网格负责检测该目标
   * 每个网格预测出$B$个bounding boxes以及它们各自的置信度（confidence scores），置信度的大小反映了预测出的bouning boxes以及其中包含某个目标的可靠度。该置信度在形式上被定义为$\text{Pr(Object)}  \cdot \text{IOU}^{\text{truth}}_{\text{pred}}$，即不存在目标时置信度应当为$0$，否则希望得到置信度等于预测出的box于真实box之间的IOU
   * 每个bounding box除了置信度外还包含$x$、$y$、$w$、$h$这几个预测值，$(x, y)$表示目标的bounding box的中心点相对于其对应的网格的坐标，$w$、$h$则是目标相对于整个图像的宽度和高度
   * 每个网格还要预测该网格种存在某个目标的条件下，$C$种类型的目标存在的概率，即$\text{Pr}(\text{Class}_i \vert \text{Object})$。尽管一个网格中存在多个bounding boxes，只预测一组各类别的存在概率。
   * 在测试时有：$$\text{Pr}(\text{Class}_i \vert \text{Object}) \cdot \text{Pr}(\text{Object}) \cdot \text{IOU}^{\text{truth}}_{\text{pred}} = \text{Pr}(\text{Class}_i) \cdot \text{IOU}^{\text{truth}}_{\text{pred}}$$
     这样将得到各box中各类目标的置信度，该置信度同时说明了box中存在某类目标的概率以及box与该目标的匹配程度。
   * 这样，整个模型预测出来的结果大小将为$S \times S \times (B \cdot 5 + C)$:
    ![Model](https://i.loli.net/2019/04/24/5cbfe84fd69b6.png)
    作者在包含$20$种类型的PASCAL VOC数据集上测试的YOLO，用到的$S = 7$、$B = 2$ $C = 20$，因此输出的大小为$7 \times 7 \times 30$

5. 实现细节：
   * 整个CNN的结构受GoogLeNet影响，整个YOLO网络由$24$个卷积层、$2$个全连接层构成，与GoogLeNet种的Inception结构稍有不同，这里只用到了$1\times1$、$3 \times 3$卷积：
   ![20190424151209.png](https://i.loli.net/2019/04/24/5cc00c4dd0368.png)
   * 首先使用了ImageNet千类竞赛数据集对CNN进行了预训练，预训练时用到了前$20$个卷积层外加一个平均池化层和一个全连接层。经过一个星期的训练后，在ImageNet 2012的验证集上获得了单一裁剪图上$88\%$的top-5准确率。所有训练过程都是用Darknet框架完成。后面参考他人的研究，再添加了$4$个卷积层和$2$个全连接层，其中的权重进行的是随机初始化。
   * 最后一层要输出各类型概率以及bounding box的坐标。通过图像的带大小将bounding box的大小进行了标准化，从而使长度和宽度都在$0$到$1$之间。各box的中心坐标$x$和$y$被参数化为各网格单元位置的偏移量，从而它们的值也在$0$到$1$之间。
   * 除最后一层用的是线性激活函数外，其他各层由用的如下Leaky-ReLU：$$\phi(x) = \begin{cases} x, & x \gt 0 \\\ 0.1x, & \text{otherwise} \end{cases}$$
   * 因为均方误差优化起来很方便，因此选用它为损失函数。然而这会使分类带来的误差与定位带来误差的权重一致，且在不包含任何目标的网格上，置信度很快被置为$0$，往往会使包含目标的网格上的梯度变化剧烈，而造成模型不稳定而在训练的早期就发散。为修正这些问题，于是用参数$\lambda_{\text{coord}} = 5$来增加由bounding box的坐标预测带来的损失，参数$\lambda_{\text{noobj}} = 0.5$来降低不包含目标时带来的损失
   * 均方误差还会使大boxes和小boxes的预测上带来误差的权重一致，误差的衡量标准应该：比起小boxes，对大boxes的预测上出现一些小偏差更可以接受。为实现这个标准，于是使模型预测输出bounding box高度、宽度的平方根而非直接的高度、宽度。
   * 每个网格中将多个bounding boxes预测器，然而训练过程中只希望各目标各由一个bounding box预测器负责，因此将某个目标的检测任务分配给当前预测出来的bounding box和真实box的IOU值最大的那个预测器负责。
   * 用到的损失函数的完整表达式：
    ![损失函数](https://i.loli.net/2019/04/24/5cc01cfc7f886.png)
    其中$\mathbb{1}_i^{\text{obj}}$代表目标是否存在第$i$个网格上且$\mathbb{1}_{ij}^{\text{obj}}$则代表第$i$个网格中预测任务由其中的第$j$个bounding box预测器负责。注意到，当目标只是存在于某个网格中时，损失函数只对其分类错误作出惩罚，如果某个网格中存在负责预测实际边框的预测器，则仅对其bounding box坐标预测错误作出惩罚。
   * YOLO网络在PASCAL VOC 2007、2012的训练集和验证集上训练了135 epochs， 训练过程的批量大小为$64$，动量为$0.9$及$0.0005$的衰减。为防止初始时学习率过高导致梯度不稳定，训练第一个epoch时，慢慢将学习率从$10^{-3}$提升到$10^{-2}$，之后用$10^{-2}$训练$75$个epochs，$10^{-3}$训练$30$个epochs，最后用$10^{-4}$训练$30$个epochs。为防止过拟合，在第一个全连接层后使用了$0.5$比例的Dropout，还用到了一些方法进行数据扩增。

### CS20-Lecture4
#### Logistic Regression