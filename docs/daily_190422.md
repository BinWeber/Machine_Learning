writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())
### CS20-Lecture_2
可将constants、variables、operators统称为ops
#### Constants
* tf.Session.run(fetches, feed_dict, options, run_metadata)
* tf.constant()用来创建常量
* tf.zeros_like(x) x.shape大小的零tensor
* tf.fill(dims, value) dims维全为value
* tf.line_space(start, stop, num) num个start到stop的值
* tf.range(start, limit, stride) 不可迭代
* tf.set_random_seed(seed) 种子
* 随机数：
  ![随机方法](https://i.loli.net/2019/04/22/5cbd652121d14.png)
* 多种除法：
  ![除法](https://i.loli.net/2019/04/22/5cbd6582b3bc8.png)
* 数据类型，与numpy互通： 
  ![数据类型](https://i.loli.net/2019/04/22/5cbd662d97aae.png)
* Tensorflow中Constant被保存在protobuf中，其很大时会使加载图的开销变大，一般只用它保存基本数据类型的数据，而用Variables或readers来保存需要占用很多内存的数据

#### Variables
* Variables用来存储变量，创建方法:
![创建variables](https://i.loli.net/2019/04/22/5cbd69c1721f9.png)
* 推荐使用tf.get_variable来创建Variables:
  ![tf.get_variable](https://i.loli.net/2019/04/22/5cbd7fc4628f0.png)
* tf.constant是一个op，tf.Variable则是一个包含多种op的类：
  ![包含多种op](https://i.loli.net/2019/04/22/5cbd6a80ee374.png)
* 使用Variables前一定需要先进行初始化op，且任何op需要放入tf.Session.run()中才能真正运行：
```python
W = tf.Variable(tf.zeros([784, 10]))
with tf.Session() as sess:
    sess.run(tf.globel_variables_initializer()) # 全局初始h化
    sess.run(tf.variable_initializer([a, b])) # 部分初始化
    sess.run(W.initializer) # 单独初始化
 ```
 * 可用tf.report_uninitialized_variable()这个op来获取未被初始化的Variables
 * tf.Variable.eval() 获取Variables实值的op
 * tf.Variable.assign() 给Variables分配值的op，**实际上初始化op就是用assign分配一个值，因此assign前不需要初始化**
   ![intializer源码](https://i.loli.net/2019/04/22/5cbd81ed42d31.png)
 * assign_add(x)、assign_sub(x) Variable加减x
 * 每个Session将维护自己run过的op
 * 依赖控制：
   ![依赖](https://i.loli.net/2019/04/22/5cbd6fd2bd6bf.png)

#### Placeholder（old way）
* 一个Tensorflow程序通常分为两个阶段：
  1. 构建一张graph，此时不需要知道任何确切的值，相当于用形参定义函数
  2. 使用seesion来执行graph中的每个操作
* sess = tf.InteractiveSession() 使用可交互的session，就可以不需要特别声明一个sess再进行各种op，后面可以tf.get_default_session()返回默认session
* tf.palceholder(dtype, shape, name)，Placeholder用来指示必须从外部投喂的tensor数据，其实值在Session.run的feed_dict中以字典的形式给出：
```python
a = tf.placeholder(tf.float32, shape=[3])
b = tf.constant([5, 5, 5], tf.float32)
c = a + b

with tf.Session() as sess:
    print(sess.run(c, feed_dict={a: [1, 2, 3]}))
```
* 各种ops都可以通过feed_dict来投喂数据，可用tf.Graph.is_feedable(tensor)验证某个tensor是否可投喂：
  ![给ops投喂](https://i.loli.net/2019/04/22/5cbd75d87a897.png)
* tf.get_default_graph().as_grpah_def() 获取graph的定义情况
* 各op分别用别名进行定义，而不要偷懒写成下面的代码：
  ![lazy loading](https://i.loli.net/2019/04/22/5cbd79c98147e.png)
  这会生成很多临时节点，造成不必要的开销：
  ![graph](https://i.loli.net/2019/04/22/5cbd7a6b900e9.png)


  